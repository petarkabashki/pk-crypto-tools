{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext iminizinc\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "# import ipywidgets as widgets\n",
    "from ipywidgets import *\n",
    "from IPython.display import display\n",
    "import IPython\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "# import talib\n",
    "import pandas_ta as ta\n",
    "# from talib.abstract import *\n",
    "from math import *\n",
    "from collections import OrderedDict\n",
    "# import vectorbt as vbt    \n",
    "import json\n",
    "from decimal import *\n",
    "getcontext().prec = 6\n",
    "import seaborn as sns\n",
    "from scipy.signal import find_peaks, peak_widths\n",
    "import pickle\n",
    "from scipy.signal import argrelextrema, argrelmax, argrelmin\n",
    "\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from research.pkg.lib import *\n",
    "\n",
    "\n",
    "# import mplfinance as mpf\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['lines.linewidth'] = 1 \n",
    "\n",
    "mpl.rcParams.update({'font.size': 10, 'lines.linewidth': 1, 'figure.dpi': 300})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minizinc import Instance, Model, Solver, Status as mzStatus\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification, make_blobs\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def call_mzn_model(model_name,model_params):\n",
    "    with open(f'pars-{model_name}.dzn.json', 'w+') as f: f.write(json.dumps(model_params, indent=2))\n",
    "\n",
    "    # print('Model params:', model_params)\n",
    "\n",
    "    mzn_model = Model(f'{model_name}.mzn')\n",
    "    gecode = Solver.lookup(\"gecode\")\n",
    "    instance = Instance(gecode, mzn_model)\n",
    "\n",
    "    for k,v in model_params.items(): instance[k] = v\n",
    "    result = instance.solve()\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_candles(wdf, ax=None, kwargs={}):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(**kwargs)\n",
    "\n",
    "    up, down = wdf[wdf.close >= wdf.open], wdf[wdf.close < wdf.open]\n",
    "    col1,col2 = 'green','red'\n",
    "    width, width2 = 2, .2\n",
    "    # Plotting up prices of the stock\n",
    "    ax.bar(up.index, up.close-up.open, width, bottom=up.open, color=col1)\n",
    "    ax.bar(up.index, up.high-up.close, width2, bottom=up.close, color=col1)\n",
    "    ax.bar(up.index, up.low-up.open, width2, bottom=up.open, color=col1)\n",
    "    # Plotting down prices of the stock\n",
    "    ax.bar(down.index, down.close-down.open, width, bottom=down.open, color=col2)\n",
    "    ax.bar(down.index, down.high-down.open, width2, bottom=down.open, color=col2)\n",
    "    ax.bar(down.index, down.low-down.close, width2, bottom=down.close, color=col2)    \n",
    "    plt.xticks(rotation=30, ha='right')\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = 'BTC_USDT'\n",
    "timeframe = '2h'\n",
    "\n",
    "exchange = 'binance'\n",
    "odf = pd.read_json(f'../freq-user-data/data/{exchange}/{pair}-{timeframe}.json'\n",
    "# exchange = 'kucoin'\n",
    "# odf = pd.read_json(f'../../freq-user-data/data/{exchange}/futures/{pair}-{timeframe}-futures.json'\n",
    ").dropna().set_axis(['timestamp', 'open', 'high', 'low', 'close', 'volume'], axis=1\n",
    ").assign(dtime=lambda x: pd.to_datetime(x['timestamp'], unit='ms', utc=False)\n",
    ").set_index('dtime').sort_index()\n",
    "\n",
    "print(odf.shape)\n",
    "odf.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odf['boL'] = odf[['open', 'close']].min(axis=1)\n",
    "odf['boH'] = odf[['open', 'close']].max(axis=1)\n",
    "# odf['dirF1'] = odf.cadir.shift(-1).ffill().astype(int)\n",
    "###\n",
    "odf['cadir'] = 1 - 2*(odf.close < odf.open).astype(int)\n",
    "# wdf\n",
    "mzn_res = call_mzn_model('last-such', {'markers': odf.cadir.values.tolist()})\n",
    "odf['n_prev'] = mzn_res['prev']\n",
    "\n",
    "# odf['f_6_close_max'] = odf.close.rolling(6).max().shift(-6)\n",
    "# roll18 = odf.rolling(18)\n",
    "# odf['l_18_std']\n",
    "\n",
    "###\n",
    "odf.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_indicators(wdf, lag):\n",
    "    ###\n",
    "    laRoll = wdf.rolling(window=lag)\n",
    "    wdf[f'laMean'] = laRoll.boL.mean()#.bfill()\n",
    "    wdf[f'laMin'] = laRoll.boL.min()#.bfill()\n",
    "    wdf[f'laMax'] = laRoll.boL.max()#.bfill()\n",
    "    wdf[f'laStd'] = laRoll.boL.std() \n",
    "    wdf[f'laZScore'] = (wdf.close - wdf.laMean) / wdf.laStd #.bfill()\n",
    "\n",
    "    laRoll = wdf.rolling(window=lag)\n",
    "    wdf[f'wd2laMeanP'] = wdf.low.divide(wdf.laMean).apply(np.log) * (wdf.laMean > wdf.low)\n",
    "    wdf[f'wdSum'] = laRoll.wd2laMeanP.sum()\n",
    "    wdf[f'wdMin'] = laRoll.wd2laMeanP.min()\n",
    "\n",
    "    for wlag in [12,24,36,72]:\n",
    "        wdf[f'c_{wlag}_min'] = wdf.close.rolling(wlag).min()\n",
    "        wdf[f'c_{wlag}_max'] = wdf.close.rolling(wlag).max()\n",
    "        wdf[f'l_{wlag}_min'] = wdf.low.rolling(wlag).min()\n",
    "        wdf[f'h_{wlag}_max'] = wdf.high.rolling(wlag).max()\n",
    "    # wdf[f'l_18_min'] = wdf.close.rolling(18).min()\n",
    "    # wdf[f'l_18_max'] = wdf.close.rolling(18).max()\n",
    "    # wdf[f'l_12_min'] = wdf.close.rolling(12).min()\n",
    "    # wdf[f'l_12_max'] = wdf.close.rolling(12).max()\n",
    "    ###\n",
    "    # for local maxima\n",
    "    # iUps = argrelextrema(wdf.close.values, np.greater, order=xOrd)\n",
    "    # iDns = argrelextrema(wdf.close.values, np.less, order=xOrd)\n",
    "    # ixUps = wdf.index[iUps]\n",
    "    # ixDns = wdf.index[iDns]\n",
    "    ###\n",
    "    return wdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdf = add_indicators(wdf=odf.copy(), lag=4,)\n",
    "wdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "\n",
    "# logging.basicConfig(filename=\"minizinc-python.log\", level=logging.DEBUG)\n",
    "wdf = None\n",
    "sig = None\n",
    "def printer(ws, xOrd, laZScore, par_wick):\n",
    "    global wdf, sig\n",
    "    wstart = ws * wlen\n",
    "    wend = wstart + wlen\n",
    "    wdf = odf.iloc[wstart:wend].copy()\n",
    "\n",
    "    wdf = add_indicators(wdf, lag=4)\n",
    "    sig = ((wdf.laZScore < laZScore) & (wdf.cadir == -1))\n",
    "\n",
    "    # isig = wdf[sig].index\n",
    "    \n",
    "    ###\n",
    "    fig = plt.figure(figsize=(15,5))\n",
    "    # fig, (ax1,ax2) = plt.subplots(2,1, height_ratios=[2,1], sharex=True)\n",
    "    plt.tight_layout()\n",
    "    ax1,ax2 = fig.subplots(2,1, height_ratios=[2,1], sharex=True)\n",
    "    wdf.close.plot(ax=ax1, lw=0.5)\n",
    "    for i in wdf.index[sig]: \n",
    "        for ax in [ax1]:\n",
    "            ax.axvline(i, lw=2, alpha=0.2)\n",
    "    wdf.wdSum.plot(ax=ax2, secondary_y=True, legend='wdSum')\n",
    "    wdf.wdMin.plot(ax=ax2, legend=True)\n",
    "    wdf.laZScore.plot(ax=ax1, secondary_y=True)\n",
    "    # ax1.set_label(True)\n",
    "    # ax1.scatter(ixUps, wdf.close[ixUps], c='r', alpha=0.3, s=50)\n",
    "    # ax1.scatter(ixDns, wdf.close[ixDns], c='g', alpha=0.3, s=50)\n",
    "    # ax2.plot(wdf.index,wdf.wdSum, c='b')\n",
    "    plot_candles(wdf,ax=ax1)\n",
    "    \n",
    "    # ax1.scatter(ix_dpeaks, wdf.loc[ix_dpeaks].close, c='g', alpha=0.3, s=100)\n",
    "wlen = 2000\n",
    "x = interact(printer, \n",
    "         ws=IntSlider(min=0, max=odf.shape[0] // wlen, step=1, value=50, description='wn'), \n",
    "         xOrd=IntSlider(min=1,max=15,value=6, description='XOrd'),\n",
    "         laZScore=FloatText(min=0.,max=0.10,step=0.001, value=0.0005, description='laZScore'), \n",
    "         par_wick=FloatText(min=0.,max=0.05,step=0.001, description='wick'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wdf.index[sig]\n",
    "# laRoll"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# wdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from adspy_shared_utilities import plot_class_regions_for_classifier\n",
    "\n",
    "adf = wdf[wdf.laZScore >= 0.0005 ].dropna()\n",
    "X_wdf = adf[['laStd','wdMin']].values\n",
    "y_wdf = adf.dirF1.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_wdf, y_wdf, random_state=0)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_trainS = scaler.fit_transform(X_train)\n",
    "X_testS = scaler.transform(X_test)\n",
    "\n",
    "nbclf = GaussianNB().fit(X_train, y_train)\n",
    "plot_class_regions_for_classifier(nbclf, X_trainS, y_train, X_testS, y_test,\n",
    "                                 'Gaussian Naive Bayes classifier: Dataset 1', gkwargs={'figsize':(15,5)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient-Boosted Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "adf = wdf[wdf.laZScore >= 0.0005 ].dropna()\n",
    "X_wdf = adf[['laStd', 'wdSum']].values\n",
    "y_wdf = adf.dirF1.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_wdf, y_wdf, random_state=0)\n",
    "\n",
    "# clf = GradientBoostingClassifier(random_state = 0)\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# print('(learning_rate=0.1, max_depth=3)')\n",
    "# print('Accuracy of GBDT classifier on training set: {:.2f}'\n",
    "#      .format(clf.score(X_train, y_train)))\n",
    "# print('Accuracy of GBDT classifier on test set: {:.2f}\\n'\n",
    "#      .format(clf.score(X_test, y_test)))\n",
    "\n",
    "clf = GradientBoostingClassifier(learning_rate = 0.1, max_depth = 5, random_state = 0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print('(learning_rate=0.01, max_depth=2)')\n",
    "print('Accuracy of GBDT classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))\n",
    "print('Accuracy of GBDT classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Nets Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = 'BTC_USDT'\n",
    "timeframe = '2h'\n",
    "\n",
    "exchange = 'binance'\n",
    "odf = pd.read_json(f'../freq-user-data/data/{exchange}/{pair}-{timeframe}.json'\n",
    "# exchange = 'kucoin'\n",
    "# odf = pd.read_json(f'../../freq-user-data/data/{exchange}/futures/{pair}-{timeframe}-futures.json'\n",
    ").dropna().set_axis(['timestamp', 'open', 'high', 'low', 'close', 'volume'], axis=1\n",
    ").assign(dtime=lambda x: pd.to_datetime(x['timestamp'], unit='ms', utc=False)\n",
    ").set_index('dtime').sort_index()\n",
    "\n",
    "print(odf.shape)\n",
    "odf.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from adspy_shared_utilities import plot_class_regions_for_classifier_subplot\n",
    "\n",
    "wdf = wdf.dropna()\n",
    "X_wdf = wdf[['laStd','wdMin', 'n_prev']].values\n",
    "y_wdf = wdf.dirF1.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_wdf, y_wdf, random_state=0)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_trainS = scaler.fit_transform(X_train)\n",
    "X_testS = scaler.transform(X_test)\n",
    "\n",
    "fig, subaxes = plt.subplots(3, 1, figsize=(15,6))\n",
    "\n",
    "for units, axis in zip([10, 100], subaxes):\n",
    "    nnclf = MLPClassifier(hidden_layer_sizes = [units]* 2, solver='lbfgs',\n",
    "                         random_state = 0).fit(X_trainS, y_train)\n",
    "    \n",
    "    title = 'Dataset 1: Neural net classifier, 1 layer, {} units'.format(units)\n",
    "    \n",
    "    # plot_class_regions_for_classifier_subplot(nnclf, X_trainS, y_train,\n",
    "    #                                          X_testS, y_test, title, axis)\n",
    "    # plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_test_results = pd.DataFrame(columns=['layers', 'units', 'tp', 'fp', 'tn', 'fn', 'precision', 'recall'])\n",
    "df_test_results.set_index(['layers', 'units'])\n",
    "df_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xdf = add_indicators(wdf=odf.copy().dropna(), lag=4)\n",
    "xdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================\n",
      "Neural net classifier, 2 layer, 80 units\n",
      "Train score = 0.87, Test score = 0.89\n",
      "---------------------------------------------------------------\n",
      "Training confusion_matrix: \n",
      "[[349   2]\n",
      " [ 51  12]]\n",
      "----------\n",
      "Testing confusion matrix: \n",
      "[[118   0]\n",
      " [ 15   5]]\n",
      "================================================================\n",
      "Neural net classifier, 3 layer, 10 units\n",
      "Train score = 0.85, Test score = 0.86\n",
      "---------------------------------------------------------------\n",
      "Training confusion_matrix: \n",
      "[[351   0]\n",
      " [ 63   0]]\n",
      "----------\n",
      "Testing confusion matrix: \n",
      "[[118   0]\n",
      " [ 20   0]]\n",
      "================================================================\n",
      "Neural net classifier, 3 layer, 15 units\n",
      "Train score = 0.85, Test score = 0.86\n",
      "---------------------------------------------------------------\n",
      "Training confusion_matrix: \n",
      "[[351   0]\n",
      " [ 63   0]]\n",
      "----------\n",
      "Testing confusion matrix: \n",
      "[[118   0]\n",
      " [ 20   0]]\n",
      "================================================================\n",
      "Neural net classifier, 3 layer, 20 units\n",
      "Train score = 0.85, Test score = 0.86\n",
      "---------------------------------------------------------------\n",
      "Training confusion_matrix: \n",
      "[[351   0]\n",
      " [ 63   0]]\n",
      "----------\n",
      "Testing confusion matrix: \n",
      "[[118   0]\n",
      " [ 20   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grenada/miniconda3/envs/py310/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================\n",
      "Neural net classifier, 3 layer, 30 units\n",
      "Train score = 0.86, Test score = 0.86\n",
      "---------------------------------------------------------------\n",
      "Training confusion_matrix: \n",
      "[[350   1]\n",
      " [ 57   6]]\n",
      "----------\n",
      "Testing confusion matrix: \n",
      "[[118   0]\n",
      " [ 20   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grenada/miniconda3/envs/py310/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================\n",
      "Neural net classifier, 3 layer, 40 units\n",
      "Train score = 0.87, Test score = 0.88\n",
      "---------------------------------------------------------------\n",
      "Training confusion_matrix: \n",
      "[[343   8]\n",
      " [ 46  17]]\n",
      "----------\n",
      "Testing confusion matrix: \n",
      "[[115   3]\n",
      " [ 14   6]]\n",
      "================================================================\n",
      "Neural net classifier, 3 layer, 50 units\n",
      "Train score = 0.86, Test score = 0.86\n",
      "---------------------------------------------------------------\n",
      "Training confusion_matrix: \n",
      "[[351   0]\n",
      " [ 56   7]]\n",
      "----------\n",
      "Testing confusion matrix: \n",
      "[[118   0]\n",
      " [ 20   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grenada/miniconda3/envs/py310/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================\n",
      "Neural net classifier, 3 layer, 60 units\n",
      "Train score = 0.87, Test score = 0.88\n",
      "---------------------------------------------------------------\n",
      "Training confusion_matrix: \n",
      "[[349   2]\n",
      " [ 52  11]]\n",
      "----------\n",
      "Testing confusion matrix: \n",
      "[[118   0]\n",
      " [ 17   3]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grenada/miniconda3/envs/py310/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================\n",
      "Neural net classifier, 3 layer, 80 units\n",
      "Train score = 0.88, Test score = 0.90\n",
      "---------------------------------------------------------------\n",
      "Training confusion_matrix: \n",
      "[[349   2]\n",
      " [ 47  16]]\n",
      "----------\n",
      "Testing confusion matrix: \n",
      "[[118   0]\n",
      " [ 14   6]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grenada/miniconda3/envs/py310/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/grenada/miniconda3/envs/py310/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================\n",
      "Neural net classifier, 4 layer, 10 units\n",
      "Train score = 0.85, Test score = 0.86\n",
      "---------------------------------------------------------------\n",
      "Training confusion_matrix: \n",
      "[[351   0]\n",
      " [ 63   0]]\n",
      "----------\n",
      "Testing confusion matrix: \n",
      "[[118   0]\n",
      " [ 20   0]]\n",
      "================================================================\n",
      "Neural net classifier, 4 layer, 15 units\n",
      "Train score = 0.87, Test score = 0.88\n",
      "---------------------------------------------------------------\n",
      "Training confusion_matrix: \n",
      "[[349   2]\n",
      " [ 53  10]]\n",
      "----------\n",
      "Testing confusion matrix: \n",
      "[[118   0]\n",
      " [ 17   3]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grenada/miniconda3/envs/py310/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================\n",
      "Neural net classifier, 4 layer, 20 units\n",
      "Train score = 0.87, Test score = 0.90\n",
      "---------------------------------------------------------------\n",
      "Training confusion_matrix: \n",
      "[[346   5]\n",
      " [ 49  14]]\n",
      "----------\n",
      "Testing confusion matrix: \n",
      "[[118   0]\n",
      " [ 14   6]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grenada/miniconda3/envs/py310/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================\n",
      "Neural net classifier, 4 layer, 30 units\n",
      "Train score = 0.86, Test score = 0.87\n",
      "---------------------------------------------------------------\n",
      "Training confusion_matrix: \n",
      "[[348   3]\n",
      " [ 54   9]]\n",
      "----------\n",
      "Testing confusion matrix: \n",
      "[[118   0]\n",
      " [ 18   2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grenada/miniconda3/envs/py310/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================\n",
      "Neural net classifier, 4 layer, 40 units\n",
      "Train score = 0.87, Test score = 0.86\n",
      "---------------------------------------------------------------\n",
      "Training confusion_matrix: \n",
      "[[346   5]\n",
      " [ 48  15]]\n",
      "----------\n",
      "Testing confusion matrix: \n",
      "[[116   2]\n",
      " [ 17   3]]\n",
      "================================================================\n",
      "Neural net classifier, 4 layer, 50 units\n",
      "Train score = 0.88, Test score = 0.88\n",
      "---------------------------------------------------------------\n",
      "Training confusion_matrix: \n",
      "[[350   1]\n",
      " [ 50  13]]\n",
      "----------\n",
      "Testing confusion matrix: \n",
      "[[118   0]\n",
      " [ 16   4]]\n",
      "================================================================\n",
      "Neural net classifier, 4 layer, 60 units\n",
      "Train score = 0.87, Test score = 0.86\n",
      "---------------------------------------------------------------\n",
      "Training confusion_matrix: \n",
      "[[350   1]\n",
      " [ 51  12]]\n",
      "----------\n",
      "Testing confusion matrix: \n",
      "[[118   0]\n",
      " [ 20   0]]\n",
      "================================================================\n",
      "Neural net classifier, 4 layer, 80 units\n",
      "Train score = 0.86, Test score = 0.86\n",
      "---------------------------------------------------------------\n",
      "Training confusion_matrix: \n",
      "[[350   1]\n",
      " [ 55   8]]\n",
      "----------\n",
      "Testing confusion matrix: \n",
      "[[118   0]\n",
      " [ 19   1]]\n",
      "================================================================\n",
      "Neural net classifier, 5 layer, 10 units\n",
      "Train score = 0.85, Test score = 0.86\n",
      "---------------------------------------------------------------\n",
      "Training confusion_matrix: \n",
      "[[351   0]\n",
      " [ 63   0]]\n",
      "----------\n",
      "Testing confusion matrix: \n",
      "[[118   0]\n",
      " [ 20   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grenada/miniconda3/envs/py310/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================\n",
      "Neural net classifier, 5 layer, 15 units\n",
      "Train score = 0.86, Test score = 0.86\n",
      "---------------------------------------------------------------\n",
      "Training confusion_matrix: \n",
      "[[350   1]\n",
      " [ 58   5]]\n",
      "----------\n",
      "Testing confusion matrix: \n",
      "[[118   0]\n",
      " [ 20   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grenada/miniconda3/envs/py310/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================\n",
      "Neural net classifier, 5 layer, 20 units\n",
      "Train score = 0.86, Test score = 0.87\n",
      "---------------------------------------------------------------\n",
      "Training confusion_matrix: \n",
      "[[346   5]\n",
      " [ 54   9]]\n",
      "----------\n",
      "Testing confusion matrix: \n",
      "[[117   1]\n",
      " [ 17   3]]\n",
      "================================================================\n",
      "Neural net classifier, 5 layer, 30 units\n",
      "Train score = 0.89, Test score = 0.88\n",
      "---------------------------------------------------------------\n",
      "Training confusion_matrix: \n",
      "[[347   4]\n",
      " [ 43  20]]\n",
      "----------\n",
      "Testing confusion matrix: \n",
      "[[118   0]\n",
      " [ 17   3]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grenada/miniconda3/envs/py310/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================\n",
      "Neural net classifier, 5 layer, 40 units\n",
      "Train score = 0.89, Test score = 0.89\n",
      "---------------------------------------------------------------\n",
      "Training confusion_matrix: \n",
      "[[347   4]\n",
      " [ 43  20]]\n",
      "----------\n",
      "Testing confusion matrix: \n",
      "[[118   0]\n",
      " [ 15   5]]\n",
      "================================================================\n",
      "Neural net classifier, 5 layer, 50 units\n",
      "Train score = 0.89, Test score = 0.89\n",
      "---------------------------------------------------------------\n",
      "Training confusion_matrix: \n",
      "[[348   3]\n",
      " [ 41  22]]\n",
      "----------\n",
      "Testing confusion matrix: \n",
      "[[117   1]\n",
      " [ 14   6]]\n",
      "================================================================\n",
      "Neural net classifier, 5 layer, 60 units\n",
      "Train score = 0.90, Test score = 0.91\n",
      "---------------------------------------------------------------\n",
      "Training confusion_matrix: \n",
      "[[345   6]\n",
      " [ 36  27]]\n",
      "----------\n",
      "Testing confusion matrix: \n",
      "[[117   1]\n",
      " [ 12   8]]\n",
      "================================================================\n",
      "Neural net classifier, 5 layer, 80 units\n",
      "Train score = 0.86, Test score = 0.87\n",
      "---------------------------------------------------------------\n",
      "Training confusion_matrix: \n",
      "[[347   4]\n",
      " [ 54   9]]\n",
      "----------\n",
      "Testing confusion matrix: \n",
      "[[117   1]\n",
      " [ 17   3]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grenada/miniconda3/envs/py310/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/grenada/miniconda3/envs/py310/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================\n",
      "Neural net classifier, 4 layer, 10 units\n",
      "Train score = 0.85, Test score = 0.86\n",
      "---------------------------------------------------------------\n",
      "Training confusion_matrix: \n",
      "[[351   0]\n",
      " [ 63   0]]\n",
      "----------\n",
      "Testing confusion matrix: \n",
      "[[118   0]\n",
      " [ 20   0]]\n",
      "================================================================\n",
      "Neural net classifier, 4 layer, 15 units\n",
      "Train score = 0.87, Test score = 0.88\n",
      "---------------------------------------------------------------\n",
      "Training confusion_matrix: \n",
      "[[349   2]\n",
      " [ 53  10]]\n",
      "----------\n",
      "Testing confusion matrix: \n",
      "[[118   0]\n",
      " [ 17   3]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grenada/miniconda3/envs/py310/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================\n",
      "Neural net classifier, 4 layer, 20 units\n",
      "Train score = 0.87, Test score = 0.90\n",
      "---------------------------------------------------------------\n",
      "Training confusion_matrix: \n",
      "[[346   5]\n",
      " [ 49  14]]\n",
      "----------\n",
      "Testing confusion matrix: \n",
      "[[118   0]\n",
      " [ 14   6]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grenada/miniconda3/envs/py310/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================\n",
      "Neural net classifier, 4 layer, 30 units\n",
      "Train score = 0.86, Test score = 0.87\n",
      "---------------------------------------------------------------\n",
      "Training confusion_matrix: \n",
      "[[348   3]\n",
      " [ 54   9]]\n",
      "----------\n",
      "Testing confusion matrix: \n",
      "[[118   0]\n",
      " [ 18   2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grenada/miniconda3/envs/py310/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================\n",
      "Neural net classifier, 4 layer, 40 units\n",
      "Train score = 0.87, Test score = 0.86\n",
      "---------------------------------------------------------------\n",
      "Training confusion_matrix: \n",
      "[[346   5]\n",
      " [ 48  15]]\n",
      "----------\n",
      "Testing confusion matrix: \n",
      "[[116   2]\n",
      " [ 17   3]]\n",
      "================================================================\n",
      "Neural net classifier, 4 layer, 50 units\n",
      "Train score = 0.88, Test score = 0.88\n",
      "---------------------------------------------------------------\n",
      "Training confusion_matrix: \n",
      "[[350   1]\n",
      " [ 50  13]]\n",
      "----------\n",
      "Testing confusion matrix: \n",
      "[[118   0]\n",
      " [ 16   4]]\n",
      "================================================================\n",
      "Neural net classifier, 4 layer, 60 units\n",
      "Train score = 0.87, Test score = 0.86\n",
      "---------------------------------------------------------------\n",
      "Training confusion_matrix: \n",
      "[[350   1]\n",
      " [ 51  12]]\n",
      "----------\n",
      "Testing confusion matrix: \n",
      "[[118   0]\n",
      " [ 20   0]]\n",
      "================================================================\n",
      "Neural net classifier, 4 layer, 80 units\n",
      "Train score = 0.86, Test score = 0.86\n",
      "---------------------------------------------------------------\n",
      "Training confusion_matrix: \n",
      "[[350   1]\n",
      " [ 55   8]]\n",
      "----------\n",
      "Testing confusion matrix: \n",
      "[[118   0]\n",
      " [ 19   1]]\n",
      "================================================================\n",
      "Neural net classifier, 7 layer, 10 units\n",
      "Train score = 0.85, Test score = 0.86\n",
      "---------------------------------------------------------------\n",
      "Training confusion_matrix: \n",
      "[[345   6]\n",
      " [ 55   8]]\n",
      "----------\n",
      "Testing confusion matrix: \n",
      "[[116   2]\n",
      " [ 17   3]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grenada/miniconda3/envs/py310/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================\n",
      "Neural net classifier, 7 layer, 15 units\n",
      "Train score = 0.87, Test score = 0.86\n",
      "---------------------------------------------------------------\n",
      "Training confusion_matrix: \n",
      "[[350   1]\n",
      " [ 54   9]]\n",
      "----------\n",
      "Testing confusion matrix: \n",
      "[[118   0]\n",
      " [ 20   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grenada/miniconda3/envs/py310/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================\n",
      "Neural net classifier, 7 layer, 20 units\n",
      "Train score = 0.87, Test score = 0.87\n",
      "---------------------------------------------------------------\n",
      "Training confusion_matrix: \n",
      "[[342   9]\n",
      " [ 45  18]]\n",
      "----------\n",
      "Testing confusion matrix: \n",
      "[[114   4]\n",
      " [ 14   6]]\n",
      "================================================================\n",
      "Neural net classifier, 7 layer, 30 units\n",
      "Train score = 0.86, Test score = 0.87\n",
      "---------------------------------------------------------------\n",
      "Training confusion_matrix: \n",
      "[[349   2]\n",
      " [ 56   7]]\n",
      "----------\n",
      "Testing confusion matrix: \n",
      "[[118   0]\n",
      " [ 18   2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from adspy_shared_utilities import plot_class_regions_for_classifier_subplot\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import itertools\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# xdf = wdf.copy()\n",
    "# y_wdf = wdf.dirF1.values\n",
    "\n",
    "xdf = add_indicators(wdf=odf.copy().dropna(), lag=4)\n",
    "fu_N = 6\n",
    "xdf['fu_top'] = wdf.close.rolling(fu_N).max().shift(-fu_N).divide(xdf.close).apply(np.log)\n",
    "xdf['fu_bottom'] = wdf.low.rolling(fu_N).min().shift(-fu_N).divide(xdf.close).apply(np.log)\n",
    "\n",
    "xdf = xdf.dropna()\n",
    "\n",
    "perc = 0.02\n",
    "r2r = 2\n",
    "y_xdf = ((xdf.fu_top >= perc) & (xdf.fu_bottom > - perc / r2r)\n",
    "         )\n",
    "\n",
    "\n",
    "X_xdf = xdf[['open', 'high', 'low', 'close', 'volume', 'boL', 'boH',\n",
    "       'cadir', 'n_prev', 'laMean', 'laMin', 'laMax', 'laStd', 'laZScore',\n",
    "       'wd2laMeanP', 'wdSum', 'wdMin', 'c_12_min', 'c_12_max', 'l_12_min',\n",
    "       'h_12_max', 'c_24_min', 'c_24_max', 'l_24_min', 'h_24_max', 'c_36_min',\n",
    "       'c_36_max', 'l_36_min', 'h_36_max', 'c_72_min', 'c_72_max', 'l_72_min',\n",
    "       'h_72_max']].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_xdf, y_xdf, random_state=1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_trainS = scaler.fit_transform(X_train)\n",
    "X_testS = scaler.transform(X_test)\n",
    "\n",
    "# df_test_results = pd.DataFrame(columns=['layers', 'units', 'tp', 'fp', 'tn', 'fn', 'precision', 'recall'])\n",
    "# df_train_results = pd.DataFrame(columns=['layers', 'units', 'tp', 'fp', 'tn', 'fn', 'precision', 'recall'])\n",
    "test_scores_rows = []\n",
    "train_conf_mat = None\n",
    "# ,60,80,100,110, 120\n",
    "for layers,units in tqdm(itertools.product([2,3,4,5,4,7,8,9,10], [10,15,20,30,40,50,60,80])):\n",
    "    clf = MLPClassifier(hidden_layer_sizes = [units]* layers, solver='adam',\n",
    "                            learning_rate='adaptive',\n",
    "                            random_state = 0, max_iter=200\n",
    "                         ).fit(X_trainS, y_train)\n",
    "    \n",
    "    train_score = clf.score(X_trainS, y_train)\n",
    "    test_score  = clf.score(X_testS, y_test)\n",
    "    print('================================================================')\n",
    "    print(f'Neural net classifier, {layers} layer, {units} units')\n",
    "    print(f\"Train score = {train_score:.2f}, Test score = {test_score:.2f}\")\n",
    "    print(f'---------------------------------------------------------------')\n",
    "\n",
    "    y_train_pred = clf.predict(X_trainS)\n",
    "    train_conf_mat = confusion_matrix(y_train, y_train_pred)\n",
    "    print(f'Training confusion_matrix: \\n{train_conf_mat}')\n",
    "    # train_precision = precision_score(y_train, y_train_pred)\n",
    "    # train_recall = recall_score(y_train, y_train_pred)\n",
    "\n",
    "\n",
    "    # print(f'Train precision = {round(train_precision,2)}, recall = {round(train_recall,2)}')\n",
    "     \n",
    "    print(f'----------')\n",
    "    y_test_pred = clf.predict(X_testS)\n",
    "    test_conf_mat = confusion_matrix(y_test, y_test_pred)\n",
    "    print(f'Testing confusion matrix: \\n{test_conf_mat}')\n",
    "    # test_precision = precision_score(y_test, y_test_pred)\n",
    "    # test_recall = recall_score(y_test, y_test_pred)\n",
    "    # print(f'Test precision = {round(test_precision,2)}, recall = {round(test_recall,2)}')\n",
    "\n",
    "    # df_train_results.append({'layers': layers, 'units': units, 'tp': tr_tp, 'fn': tr_fn, 'tn': tr_tn, 'fp': tr_fp})\n",
    "    # test_scores_rows.append({'layers': layers, 'units': units, 'tp': tst_tp, 'fn': tst_fn, 'tn': tst_tn, 'fp': tst_fp})\n",
    "\n",
    "    test_scores_rows.append({'layers': layers, 'units': units, 'test_conf_mat': test_conf_mat, 'train_conf_mat': train_conf_mat})\n",
    "\n",
    "\n",
    "    # df_test_scores.loc([layers, units]) = {'tp': tst_tp, 'fn': tst_fn, 'tn': tst_tn, 'fp': tst_fp})\n",
    "\n",
    "#     break\n",
    "    # plot_class_regions_for_classifier_subplot(nnclf, X_trainS, y_train,\n",
    "                                            #  X_testS, y_test, title, axis)\n",
    "    # plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.asmatrix(df_test_scores.test_conf_mat.apply(lambda x: x.ravel().tolist()).values.tolist()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_scores_rows\n",
    "df_test_scores = pd.DataFrame.from_dict(test_scores_rows)\n",
    "# df_test_scores['precision'] = df_test_scores.tp / (df_test_scores.tp + )\n",
    "# df_test_scores['test_precision'] = df_test_scores.test_conf_mat.apply(lambda x: round(1. / (1e-08 + x[1,1] + x[0,1]), 2) if (x[1,1] + x[0,1]) > 0 else 0)\n",
    "\n",
    "# df_test_scores.loc[:]['TN', 'FP', 'FN', 'TP'] = np.asmatrix(df_test_scores.test_conf_mat.apply(lambda x: x.ravel().tolist()).values.tolist())\n",
    "df_test_scores = df_test_scores.join(pd.DataFrame(np.asmatrix(df_test_scores.test_conf_mat.apply(lambda x: x.ravel().tolist()).values.tolist()), \n",
    "             columns=['TN', 'FP', 'FN', 'TP']))\n",
    "\n",
    "df_test_scores['precision'] = (df_test_scores.TP / (df_test_scores.TP + df_test_scores.FP + 1e-08)).round(2)\n",
    "df_test_scores['recall'] = (df_test_scores.TP / (df_test_scores.TP + df_test_scores.FN + 1e-08)).round(2)\n",
    "\n",
    "df_test_scores.head(20)#[df_test_scores.test_precision > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_scores[df_test_scores.precision > 0.4].sort_values(['precision', 'recall'])\n",
    "# df_test_scores[df_test_scores.test_conf_mat[1,1] > 0].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_scores.test_conf_mat.apply(lambda x: x.ravel()).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
